{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YoTVCUtTQL6c"
   },
   "source": [
    "# TP 1: LDA/QDA y optimizaci√≥n matem√°tica de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kL_4etdeizy"
   },
   "source": [
    "# Intro te√≥rica\n",
    "\n",
    "## Definici√≥n: Clasificador Bayesiano\n",
    "\n",
    "Sean $k$ poblaciones, $x \\in \\mathbb{R}^p$ puede pertenecer a cualquiera $g \\in \\mathcal{G}$ de ellas. Bajo un esquema bayesiano, se define entonces $\\pi_j \\doteq P(G = j)$ la probabilidad *a priori* de que $X$ pertenezca a la clase *j*, y se **asume conocida** la distribuci√≥n condicional de cada observable dado su clase $f_j \\doteq f_{X|G=j}$.\n",
    "\n",
    "De esta manera dicha probabilidad *a posteriori* resulta\n",
    "$$\n",
    "P(G|_{X=x} = j) = \\frac{f_{X|G=j}(x) \\cdot p_G(j)}{f_X(x)} \\propto f_j(x) \\cdot \\pi_j\n",
    "$$\n",
    "\n",
    "La regla de decisi√≥n de Bayes es entonces\n",
    "$$\n",
    "H(x) \\doteq \\arg \\max_{g \\in \\mathcal{G}} \\{ P(G|_{X=x} = j) \\} = \\arg \\max_{g \\in \\mathcal{G}} \\{ f_j(x) \\cdot \\pi_j \\}\n",
    "$$\n",
    "\n",
    "es decir, se predice a $x$ como perteneciente a la poblaci√≥n $j$ cuya probabilidad a posteriori es m√°xima.\n",
    "\n",
    "*Ojo, a no desesperar! $\\pi_j$ no es otra cosa que una constante prefijada, y $f_j$ es, en su esencia, un campo escalar de $x$ a simplemente evaluar.*\n",
    "\n",
    "## Distribuci√≥n condicional\n",
    "\n",
    "Para los clasificadores de discriminante cuadr√°tico y lineal (QDA/LDA) se asume que $X|_{G=j} \\sim \\mathcal{N}_p(\\mu_j, \\Sigma_j)$, es decir, se asume que cada poblaci√≥n sigue una distribuci√≥n normal.\n",
    "\n",
    "Por definici√≥n, se tiene entonces que para una clase $j$:\n",
    "$$\n",
    "f_j(x) = \\frac{1}{(2 \\pi)^\\frac{p}{2} \\cdot |\\Sigma_j|^\\frac{1}{2}} e^{- \\frac{1}{2}(x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j)}\n",
    "$$\n",
    "\n",
    "Aplicando logaritmo (que al ser una funci√≥n estrictamente creciente no afecta el c√°lculo de m√°ximos/m√≠nimos), queda algo mucho m√°s pr√°ctico de trabajar:\n",
    "\n",
    "$$\n",
    "\\log{f_j(x)} = -\\frac{1}{2}\\log |\\Sigma_j| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j) + C\n",
    "$$\n",
    "\n",
    "Observar que en este caso $C=-\\frac{p}{2} \\log(2\\pi)$, pero no se tiene en cuenta ya que al tener una constante aditiva en todas las clases, no afecta al c√°lculo del m√°ximo.\n",
    "\n",
    "## LDA\n",
    "\n",
    "En el caso de LDA se hace una suposici√≥n extra, que es $X|_{G=j} \\sim \\mathcal{N}_p(\\mu_j, \\Sigma)$, es decir que las poblaciones no s√≥lo siguen una distribuci√≥n normal sino que son de igual matriz de covarianzas. Reemplazando arriba se obtiene entonces:\n",
    "\n",
    "$$\n",
    "\\log{f_j(x)} =  -\\frac{1}{2}\\log |\\Sigma| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j) + C\n",
    "$$\n",
    "\n",
    "Ahora, como $-\\frac{1}{2}\\log |\\Sigma|$ es com√∫n a todas las clases se puede incorporar a la constante aditiva y, distribuyendo y reagrupando t√©rminos sobre $(x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j)$ se obtiene finalmente:\n",
    "\n",
    "$$\n",
    "\\log{f_j(x)} =  \\mu_j^T \\Sigma^{-1} (x- \\frac{1}{2} \\mu_j) + C'\n",
    "$$\n",
    "\n",
    "## Entrenamiento/Ajuste\n",
    "\n",
    "Obs√©rvese que para ambos modelos, ajustarlos a los datos implica estimar los par√°metros $(\\mu_j, \\Sigma_j) \\; \\forall j = 1, \\dots, k$ en el caso de QDA, y $(\\mu_j, \\Sigma)$ para LDA.\n",
    "\n",
    "Estos par√°metros se estiman por m√°xima verosimilitud, de manera que los estimadores resultan:\n",
    "\n",
    "* $\\hat{\\mu}_j = \\bar{x}_j$ el promedio de los $x$ de la clase *j*\n",
    "* $\\hat{\\Sigma}_j = s^2_j$ la matriz de covarianzas estimada para cada clase *j*\n",
    "* $\\hat{\\pi}_j = f_{R_j} = \\frac{n_j}{n}$ la frecuencia relativa de la clase *j* en la muestra\n",
    "* $\\hat{\\Sigma} = \\frac{1}{n} \\sum_{j=1}^k n_j \\cdot s^2_j$ el promedio ponderado (por frecs. relativas) de las matrices de covarianzas de todas las clases. *Observar que se utiliza el estimador de MV y no el insesgado*\n",
    "\n",
    "Es importante notar que si bien todos los $\\mu, \\Sigma$ deben ser estimados, la distribuci√≥n *a priori* puede no inferirse de los datos sino asumirse previamente, utiliz√°ndose como entrada del modelo.\n",
    "\n",
    "## Predicci√≥n\n",
    "\n",
    "Para estos modelos, al igual que para cualquier clasificador Bayesiano del tipo antes visto, la estimaci√≥n de la clase es por m√©todo *plug-in* sobre la regla de decisi√≥n $H(x)$, es decir devolver la clase que maximiza $\\hat{f}_j(x) \\cdot \\hat{\\pi}_j$, o lo que es lo mismo $\\log\\hat{f}_j(x) + \\log\\hat{\\pi}_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IV8OF-SlPHbD"
   },
   "source": [
    "# C√≥digo provisto\n",
    "\n",
    "Con el fin de no retrasar al alumno con cuestiones estructurales y/o secundarias al tema que se pretende tratar, se provee una base de c√≥digo que **no es obligatoria de usar** pero se asume que resulta resulta beneficiosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrDdJRypNB-y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.linalg as LA\n",
    "from scipy.linalg import cholesky, solve_triangular\n",
    "from scipy.linalg.lapack import dtrtri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cPL33WIN2HA"
   },
   "source": [
    "## Base code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewg5e0hsNTQC"
   },
   "outputs": [],
   "source": [
    "class BaseBayesianClassifier:\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def _estimate_a_priori(self, y):\n",
    "    a_priori = np.bincount(y.flatten().astype(int)) / y.size\n",
    "    # Q3: para que sirve bincount?\n",
    "    # R3: Crea un vector con la cantidad de ocurrencias de cada entero dentro de y\n",
    "    return np.log(a_priori)\n",
    "\n",
    "  def _fit_params(self, X, y):\n",
    "    # estimate all needed parameters for given model\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
    "    # this should depend on the model used\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def fit(self, X, y, a_priori=None):\n",
    "    # if it's needed, estimate a priori probabilities\n",
    "    self.log_a_priori = self._estimate_a_priori(y) if a_priori is None else np.log(a_priori)\n",
    "\n",
    "    # now that everything else is in place, estimate all needed parameters for given model\n",
    "    self._fit_params(X, y)\n",
    "    # Q4: por que el _fit_params va al final? no se puede mover a, por ejemplo, antes de la priori?\n",
    "\n",
    "  def predict(self, X):\n",
    "    # this is actually an individual prediction encased in a for-loop\n",
    "    m_obs = X.shape[1]\n",
    "    y_hat = np.empty(m_obs, dtype=int)\n",
    "\n",
    "    for i in range(m_obs):\n",
    "      y_hat[i] = self._predict_one(X[:,i].reshape(-1,1))\n",
    "\n",
    "    # return prediction as a row vector (matching y)\n",
    "    return y_hat.reshape(1,-1)\n",
    "\n",
    "  def _predict_one(self, x):\n",
    "    # calculate all log posteriori probabilities (actually, +C)\n",
    "    log_posteriori = [ log_a_priori_i + self._predict_log_conditional(x, idx) for idx, log_a_priori_i\n",
    "                  in enumerate(self.log_a_priori) ]\n",
    "\n",
    "    # return the class that has maximum a posteriori probability\n",
    "    return np.argmax(log_posteriori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rz2FC7A5NUpN"
   },
   "outputs": [],
   "source": [
    "class QDA(BaseBayesianClassifier):\n",
    "\n",
    "  def _fit_params(self, X, y):\n",
    "    # estimate each covariance matrix\n",
    "    self.inv_covs = [LA.inv(np.cov(X[:,y.flatten()==idx], bias=True))\n",
    "                      for idx in range(len(self.log_a_priori))]\n",
    "    # Q5: por que hace falta el flatten y no se puede directamente X[:,y==idx]?\n",
    "    # R5: porque y es un vector columna y no se puede comparar con un vector fila. \n",
    "    # Flatten en este caso lo convierte en arreglo de 1D y entonces si se puede hacer la comparacion con idx.\n",
    "\n",
    "    # Q6: por que se usa bias=True en vez del default bias=False?\n",
    "    # R6: porque bias=False hace que la matriz de covarianza sea insesgada.\n",
    "\n",
    "    self.means = [X[:,y.flatten()==idx].mean(axis=1, keepdims=True)\n",
    "                  for idx in range(len(self.log_a_priori))]\n",
    "    # Q7: que hace axis=1? por que no axis=0?\n",
    "    # R7: axis=1 indica que el promedio se debe calcular por columnas y no por filas.\n",
    "\n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
    "    # this should depend on the model used\n",
    "    inv_cov = self.inv_covs[class_idx]\n",
    "    unbiased_x =  x - self.means[class_idx]\n",
    "    return 0.5*np.log(LA.det(inv_cov)) -0.5 * unbiased_x.T @ inv_cov @ unbiased_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lZbID0WNV1Y"
   },
   "outputs": [],
   "source": [
    "class TensorizedQDA(QDA):\n",
    "\n",
    "    def _fit_params(self, X, y):\n",
    "        # ask plain QDA to fit params\n",
    "        super()._fit_params(X,y)\n",
    "\n",
    "        # stack onto new dimension\n",
    "        self.tensor_inv_cov = np.stack(self.inv_covs)\n",
    "        self.tensor_means = np.stack(self.means)\n",
    "\n",
    "    def _predict_log_conditionals(self,x):\n",
    "        unbiased_x = x - self.tensor_means\n",
    "        inner_prod = unbiased_x.transpose(0,2,1) @ self.tensor_inv_cov @ unbiased_x\n",
    "\n",
    "        return 0.5*np.log(LA.det(self.tensor_inv_cov)) - 0.5 * inner_prod.flatten()\n",
    "\n",
    "    def _predict_one(self, x):\n",
    "        # return the class that has maximum a posteriori probability\n",
    "        return np.argmax(self.log_a_priori + self._predict_log_conditionals(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-WGGi_sQ-pT"
   },
   "outputs": [],
   "source": [
    "class QDA_Chol1(BaseBayesianClassifier):\n",
    "  def _fit_params(self, X, y):\n",
    "    self.L_invs = [\n",
    "        inv(cholesky(np.cov(X[:,y.flatten()==idx], bias=True), lower=True))\n",
    "        for idx in range(len(self.log_a_priori))\n",
    "    ]\n",
    "\n",
    "    self.means = [X[:,y.flatten()==idx].mean(axis=1, keepdims=True)\n",
    "                  for idx in range(len(self.log_a_priori))]\n",
    "\n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    L_inv = self.L_invs[class_idx]\n",
    "    unbiased_x =  x - self.means[class_idx]\n",
    "\n",
    "    y = L_inv @ unbiased_x\n",
    "\n",
    "    return np.log(L_inv.diagonal().prod()) -0.5 * (y**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5DNLtYbQsHi"
   },
   "outputs": [],
   "source": [
    "class QDA_Chol2(BaseBayesianClassifier):\n",
    "  def _fit_params(self, X, y):\n",
    "    self.Ls = [\n",
    "        cholesky(np.cov(X[:,y.flatten()==idx], bias=True), lower=True)\n",
    "        for idx in range(len(self.log_a_priori))\n",
    "    ]\n",
    "\n",
    "    self.means = [X[:,y.flatten()==idx].mean(axis=1, keepdims=True)\n",
    "                  for idx in range(len(self.log_a_priori))]\n",
    "\n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    L = self.Ls[class_idx]\n",
    "    unbiased_x =  x - self.means[class_idx]\n",
    "\n",
    "    y = solve_triangular(L, unbiased_x, lower=True)\n",
    "\n",
    "    return -np.log(L.diagonal().prod()) -0.5 * (y**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0dRvYVQRCgc"
   },
   "outputs": [],
   "source": [
    "class QDA_Chol3(BaseBayesianClassifier):\n",
    "  def _fit_params(self, X, y):\n",
    "    self.L_invs = [\n",
    "        dtrtri(cholesky(np.cov(X[:,y.flatten()==idx], bias=True), lower=True), lower=1)[0]\n",
    "        for idx in range(len(self.log_a_priori))\n",
    "    ]\n",
    "\n",
    "    self.means = [X[:,y.flatten()==idx].mean(axis=1, keepdims=True)\n",
    "                  for idx in range(len(self.log_a_priori))]\n",
    "\n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    L_inv = self.L_invs[class_idx]\n",
    "    unbiased_x =  x - self.means[class_idx]\n",
    "\n",
    "    y = L_inv @ unbiased_x\n",
    "\n",
    "    return np.log(L_inv.diagonal().prod()) -0.5 * (y**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCtrHQDuN6R4"
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rasInBMFNzUH"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, fetch_openml, load_wine\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_iris_dataset():\n",
    "  data = load_iris()\n",
    "  X_full = data.data\n",
    "  y_full = np.array([data.target_names[y] for y in data.target.reshape(-1,1)])\n",
    "  return X_full, y_full\n",
    "\n",
    "def get_penguins_dataset():\n",
    "    # get data\n",
    "    df, tgt = fetch_openml(name=\"penguins\", return_X_y=True, as_frame=True, parser='auto')\n",
    "\n",
    "    # drop non-numeric columns\n",
    "    df.drop(columns=[\"island\",\"sex\"], inplace=True)\n",
    "\n",
    "    # drop rows with missing values\n",
    "    mask = df.isna().sum(axis=1) == 0\n",
    "    df = df[mask]\n",
    "    tgt = tgt[mask]\n",
    "\n",
    "    return df.values, tgt.to_numpy().reshape(-1,1)\n",
    "\n",
    "def get_wine_dataset():\n",
    "    # get data\n",
    "    data = load_wine()\n",
    "    X_full = data.data\n",
    "    y_full = np.array([data.target_names[y] for y in data.target.reshape(-1,1)])\n",
    "    return X_full, y_full\n",
    "\n",
    "def get_letters_dataset():\n",
    "    # get data\n",
    "    letter = fetch_openml('letter', version=1, as_frame=False)\n",
    "    return letter.data, letter.target.reshape(-1,1)\n",
    "\n",
    "def label_encode(y_full):\n",
    "    return LabelEncoder().fit_transform(y_full.flatten()).reshape(y_full.shape)\n",
    "\n",
    "def split_transpose(X, y, test_size, random_state):\n",
    "    # X_train, X_test, y_train, y_test but all transposed\n",
    "    return [elem.T for elem in train_test_split(X, y, test_size=test_size, random_state=random_state)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybPkuBdDN42P"
   },
   "source": [
    "## Benchmarking\n",
    "\n",
    "Nota: esta clase fue creada bastante r√°pido y no pretende ser una plataforma s√∫per confiable sobre la que basarse, sino m√°s bien una herramienta simple con la que poder medir varios runs y agregar la informaci√≥n.\n",
    "\n",
    "En forma r√°pida, `warmup` es la cantidad de runs para warmup, `mem_runs` es la cantidad de runs en las que se mide el pico de uso de RAM y `n_runs` es la cantidad de runs en las que se miden tiempos.\n",
    "\n",
    "La raz√≥n por la que se separan es que medir memoria hace ~2.5x m√°s lento cada run, pero al mismo tiempo se estabiliza mucho m√°s r√°pido.\n",
    "\n",
    "**Importante:** tener en cuenta que los modelos que predicen en batch (usan `predict` directamente) deber√≠an consumir, como m√≠nimo, $n$ veces la memoria de los que predicen por observaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nO4Py3CeNpKu"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from numpy.random import RandomState\n",
    "import tracemalloc\n",
    "\n",
    "RNG_SEED = 6553\n",
    "\n",
    "class Benchmark:\n",
    "    def __init__(self, X, y, n_runs=1000, warmup=100, mem_runs=100, test_sz=0.3, rng_seed=RNG_SEED, same_splits=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n = n_runs\n",
    "        self.warmup = warmup\n",
    "        self.mem_runs = mem_runs\n",
    "        self.test_sz = test_sz\n",
    "        self.det = same_splits\n",
    "        if self.det:\n",
    "            self.rng_seed = rng_seed\n",
    "        else:\n",
    "            self.rng = RandomState(rng_seed)\n",
    "\n",
    "        self.data = dict()\n",
    "\n",
    "        print(\"Benching params:\")\n",
    "        print(\"Total runs:\",self.warmup+self.mem_runs+self.n)\n",
    "        print(\"Warmup runs:\",self.warmup)\n",
    "        print(\"Peak Memory usage runs:\", self.mem_runs)\n",
    "        print(\"Running time runs:\", self.n)\n",
    "        approx_test_sz = int(self.y.size * self.test_sz)\n",
    "        print(\"Train size rows (approx):\",self.y.size - approx_test_sz)\n",
    "        print(\"Test size rows (approx):\",approx_test_sz)\n",
    "        print(\"Test size fraction:\",self.test_sz)\n",
    "\n",
    "    def bench(self, model_class, **kwargs):\n",
    "        name = model_class.__name__\n",
    "        time_data = np.empty((self.n, 3), dtype=float)  # train_time, test_time, accuracy\n",
    "        mem_data = np.empty((self.mem_runs, 2), dtype=float)  # train_peak_mem, test_peak_mem\n",
    "        rng = RandomState(self.rng_seed) if self.det else self.rng\n",
    "\n",
    "\n",
    "        for i in range(self.warmup):\n",
    "            # Instantiate model with error check for unsupported parameters\n",
    "            model = model_class(**kwargs)\n",
    "\n",
    "            # Generate current train-test split\n",
    "            X_train, X_test, y_train, y_test = split_transpose(\n",
    "                self.X, self.y,\n",
    "                test_size=self.test_sz,\n",
    "                random_state=rng\n",
    "            )\n",
    "            # Run training and prediction (timing or memory measurement not recorded)\n",
    "            model.fit(X_train, y_train)\n",
    "            model.predict(X_test)\n",
    "\n",
    "        for i in tqdm(range(self.mem_runs), total=self.mem_runs, desc=f\"{name} (MEM)\"):\n",
    "\n",
    "            model = model_class(**kwargs)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = split_transpose(\n",
    "                self.X, self.y,\n",
    "                test_size=self.test_sz,\n",
    "                random_state=rng\n",
    "            )\n",
    "\n",
    "            tracemalloc.start()\n",
    "\n",
    "            t1 = time.perf_counter()\n",
    "            model.fit(X_train, y_train)\n",
    "            t2 = time.perf_counter()\n",
    "\n",
    "            _, train_peak = tracemalloc.get_traced_memory()\n",
    "            tracemalloc.reset_peak()\n",
    "\n",
    "            model.predict(X_test)\n",
    "            t3 = time.perf_counter()\n",
    "            _, test_peak = tracemalloc.get_traced_memory()\n",
    "            tracemalloc.stop()\n",
    "\n",
    "            mem_data[i,] = (\n",
    "                train_peak / (1024 * 1024),\n",
    "                test_peak / (1024 * 1024)\n",
    "            )\n",
    "\n",
    "        for i in tqdm(range(self.n), total=self.n, desc=f\"{name} (TIME)\"):\n",
    "            model = model_class(**kwargs)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = split_transpose(\n",
    "                self.X, self.y,\n",
    "                test_size=self.test_sz,\n",
    "                random_state=rng\n",
    "            )\n",
    "\n",
    "            t1 = time.perf_counter()\n",
    "            model.fit(X_train, y_train)\n",
    "            t2 = time.perf_counter()\n",
    "            preds = model.predict(X_test)\n",
    "            t3 = time.perf_counter()\n",
    "\n",
    "            time_data[i,] = (\n",
    "                (t2 - t1) * 1000,\n",
    "                (t3 - t2) * 1000,\n",
    "                (y_test.flatten() == preds.flatten()).mean()\n",
    "            )\n",
    "\n",
    "        self.data[name] = (time_data, mem_data)\n",
    "\n",
    "    def summary(self, baseline=None):\n",
    "        aux = []\n",
    "        for name, (time_data, mem_data) in self.data.items():\n",
    "            result = {\n",
    "                'model': name,\n",
    "                'train_mean_ms': time_data[:, 0].mean(),\n",
    "                'train_std_ms': time_data[:, 0].std(),\n",
    "                'test_mean_ms': time_data[:, 1].mean(),\n",
    "                'test_std_ms': time_data[:, 1].std(),\n",
    "                'mean_accuracy': time_data[:, 2].mean(),\n",
    "                'train_mem_mean_mb': mem_data[:, 0].mean(),\n",
    "                'train_mem_std_mb': mem_data[:, 0].std(),\n",
    "                'test_mem_mean_mb': mem_data[:, 1].mean(),\n",
    "                'test_mem_std_mb': mem_data[:, 1].std()\n",
    "            }\n",
    "            aux.append(result)\n",
    "        df = pd.DataFrame(aux).set_index('model')\n",
    "\n",
    "        if baseline is not None and baseline in self.data:\n",
    "            df['train_speedup'] = df.loc[baseline, 'train_mean_ms'] / df['train_mean_ms']\n",
    "            df['test_speedup'] = df.loc[baseline, 'test_mean_ms'] / df['test_mean_ms']\n",
    "            df['train_mem_reduction'] = df.loc[baseline, 'train_mem_mean_mb'] / df['train_mem_mean_mb']\n",
    "            df['test_mem_reduction'] = df.loc[baseline, 'test_mem_mean_mb'] / df['test_mem_mean_mb']\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mb5VEpEugFXW"
   },
   "source": [
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLyr4-hdgJ7e",
    "outputId": "bfa9623f-2baf-4735-96b5-c714b244b8da"
   },
   "outputs": [],
   "source": [
    "# levantamos el dataset Wine, que tiene 13 features y 178 observaciones en total\n",
    "X_full, y_full = get_wine_dataset()\n",
    "\n",
    "X_full.shape, y_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxQlFUSbgYHQ",
    "outputId": "dd396038-8bab-4ebd-b981-752526d8c98c"
   },
   "outputs": [],
   "source": [
    "# encodeamos a n√∫mero las clases\n",
    "y_full_encoded = label_encode(y_full)\n",
    "\n",
    "y_full[:5], y_full_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSBNNUOmgtsI",
    "outputId": "d29b11de-b5a9-4fa3-f009-d8780104fa64"
   },
   "outputs": [],
   "source": [
    "# generamos el benchmark\n",
    "# observar que son valores muy bajos de runs para que corra r√°pido ahora\n",
    "b = Benchmark(\n",
    "    X_full, y_full_encoded,\n",
    "    n_runs = 100,\n",
    "    warmup = 20,\n",
    "    mem_runs = 20,\n",
    "    test_sz = 0.3,\n",
    "    same_splits = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "2add89be4e944f4fbd91c5f1d459b5cb",
      "e0a05e28520841bd95e2aec19da024bd",
      "c406ae72dbf14856971c0ac3ad078062",
      "ca156cc465e1415b8df2a570abfa3ffe",
      "40416335cca64bbbad37afc46049363d",
      "4531ea3385d34454865e3c6ced188122",
      "a9bc2a66f8a84516a44d8d3ad8e885e2",
      "43ef5277fff74410bb85f09e64c37cfe",
      "d7276daf0b654112aab411ae3f14649f",
      "68a99e1ecb9741f688cb33bbfc19d5d2",
      "cec5bcb756694268abfc4eefad72f758",
      "0878ca0785b74f4fa8abce52c184ce33",
      "9cb5b6651bac47d0b99c9388def7d2e6",
      "ec4d02ef09c5492ab097ef02b9d3e2fb",
      "ed4b7065efa24e5da4f69c047647c047",
      "08dc6e2b043f409f8f8df2b63f6bc152",
      "f7bc1a202cde4351a6f98ae19393cf94",
      "caea67fec94c45a097cae720b582c68d",
      "c136c5327b804c74b0582ed04c8825dc",
      "b2d747a3bfdd4f4797f7e4b01964aa7b",
      "a5957e8514974187838fc2d43d548433",
      "38dcdaf521fe4043b7bc5fac762867e1"
     ]
    },
    "id": "zUciOjazhUu5",
    "outputId": "91fc0889-7a87-418e-9950-88371c912be9"
   },
   "outputs": [],
   "source": [
    "# bencheamos un par\n",
    "to_bench = [QDA]\n",
    "\n",
    "for model in to_bench:\n",
    "    b.bench(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "e3704aaa731c464a8d6c63c39d0b167a",
      "ee002c5199874f8db461bb1631f198ac",
      "9e38484f037e4f86be6b768459404767",
      "d670b24d966f4de1872524684ea98840",
      "74859eadc1ef4090a07e851f5949f4d6",
      "1f6553e18f4f460ebbc4b9705cfb9c3d",
      "44cc54751afe4e618d81e92e2e64ca58",
      "f1cdc4724c6d441cbebca60f1bb11aea",
      "4965b54e63794e0b80c19c150b072eda",
      "4c09e94a9e494e6daa6f59c23b8bcb4f",
      "ab3b1739c3bf4f3ba399e3a60d043ec8",
      "6bbe1b2d6f3846168244aca7ecf761f0",
      "eb6e454a891d493b88fe82442a9288e2",
      "3fad52f5ac204004afac2df2b55cbc7b",
      "2d6622ab061342f280f7fbcbc920bc00",
      "e7cdc4320bff45f6acf901b8bd9bdf1a",
      "bf6f0511eeca467c870c6a261712ca7e",
      "26d56661a9e4490c96ef5dd831fa904b",
      "ba742120ade4495d9f75b066c43b6ffb",
      "e38ba66c86764d578b97aa127e0cd9ce",
      "f87908723b244cd99144a4e1b7be8807",
      "568fd1f1b5984675bf1716520a63b7d1"
     ]
    },
    "id": "wpPhSSCNhlvG",
    "outputId": "a5302dc3-d947-47db-d96d-cf7a98152b0e"
   },
   "outputs": [],
   "source": [
    "# como es una clase, podemos seguir bencheando m√°s despu√©s\n",
    "b.bench(TensorizedQDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "bZ5-vowshr5c",
    "outputId": "f17bc091-0cf5-42b9-cd9a-1e3d61e824b0"
   },
   "outputs": [],
   "source": [
    "# hacemos un summary\n",
    "b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "09eKXqlXhwL-",
    "outputId": "d42734a6-6fd8-4b15-da84-144d4923113f"
   },
   "outputs": [],
   "source": [
    "# son muchos datos! nos quedamos con un par nom√°s\n",
    "summ = b.summary()\n",
    "\n",
    "# como es un pandas DataFrame, subseteamos columnas f√°cil\n",
    "summ[['train_mean_ms', 'test_mean_ms','mean_accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "EopB9574h8I5",
    "outputId": "c2bd86ab-3ba3-456d-c99b-d3bd131af75f"
   },
   "outputs": [],
   "source": [
    "# podemos setear un baseline para que fabrique columnas de comparaci√≥n\n",
    "summ = b.summary(baseline='QDA')\n",
    "\n",
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "z0qeE1gviFLZ",
    "outputId": "26f288da-88c0-4568-d4cb-f3d60bf5045c"
   },
   "outputs": [],
   "source": [
    "summ[[\n",
    "    'train_mean_ms', 'test_mean_ms','mean_accuracy',\n",
    "    'train_speedup', 'test_speedup',\n",
    "    'train_mem_reduction', 'test_mem_reduction'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EF80Pck2RmaC"
   },
   "source": [
    "# Consigna QDA\n",
    "\n",
    "**Notaci√≥n**: en general notamos\n",
    "\n",
    "* $k$ la cantidad de clases\n",
    "* $n$ la cantidad de observaciones\n",
    "* $p$ la cantidad de features/variables/predictores\n",
    "\n",
    "**Sugerencia:** combinaciones adecuadas de `transpose`, `stack`, `reshape` y, ocasionalmente, `flatten` y `diagonal` suele ser m√°s que suficiente. Se recomienda **fuertemente* explorar la dimensionalidad de cada elemento antes de implementar las clases.\n",
    "\n",
    "## Tensorizaci√≥n\n",
    "\n",
    "En esta secci√≥n nos vamos a ocupar de hacer que el modelo sea m√°s r√°pido para generar predicciones, observando que incurre en un doble `for` dado que predice en forma individual un escalar para cada observaci√≥n, para cada clase. Paralelizar ambos v√≠a tensorizaci√≥n suena como una gran v√≠a de mejora de tiempos.\n",
    "\n",
    "### 1) Diferencias entre `QDA`y `TensorizedQDA`\n",
    "\n",
    "1. ¬øSobre qu√© paraleliza `TensorizedQDA`? ¬øSobre las $k$ clases, las $n$ observaciones a predecir, o ambas?\n",
    "2. Analizar los shapes de `tensor_inv_covs` y `tensor_means` y explicar paso a paso c√≥mo es que `TensorizedQDA` llega a predecir lo mismo que `QDA`.\n",
    "\n",
    "### 2) Optimizaci√≥n\n",
    "\n",
    "Debido a la forma cuadr√°tica de QDA, no se puede predecir para $n$ observaciones en una sola pasada (utilizar $X \\in \\mathbb{R}^{p \\times n}$ en vez de $x \\in \\mathbb{R}^p$) sin pasar por una matriz de $n \\times n$ en donde se computan todas las interacciones entre observaciones. Se puede acceder al resultado recuperando s√≥lo la diagonal de dicha matriz, pero resulta ineficiente en tiempo y (especialmente) en memoria. A√∫n as√≠, es *posible* que el modelo funcione m√°s r√°pido.\n",
    "\n",
    "3. Implementar el modelo `FasterQDA` (se recomienda heredarlo de `TensorizedQDA`) de manera de eliminar el ciclo for en el m√©todo predict.\n",
    "4. Mostrar d√≥nde aparece la mencionada matriz de $n \\times n$, donde $n$ es la cantidad de observaciones a predecir.\n",
    "5. Demostrar que\n",
    "$$\n",
    "diag(A \\cdot B) = \\sum_{cols} A \\odot B^T = np.sum(A \\odot B^T, axis=1)\n",
    "$$ es decir, que se puede \"esquivar\" la matriz de $n \\times n$ usando matrices de $n \\times p$. Tambi√©n se puede usar, de forma equivalente,\n",
    "$$\n",
    "np.sum(A^T \\odot B, axis=0).T\n",
    "$$\n",
    "  queda a preferencia del alumno cu√°l usar.\n",
    "\n",
    "6. Utilizar la propiedad antes demostrada para reimplementar la predicci√≥n del modelo `FasterQDA` de forma eficiente en un nuevo modelo `EfficientQDA`.\n",
    "7. Comparar la performance de las 4 variantes de QDA implementadas hasta ahora (no Cholesky) ¬øQu√© se observa? A modo de opini√≥n ¬øSe condice con lo esperado?\n",
    "\n",
    "## Cholesky\n",
    "\n",
    "Hasta ahora todos los esfuerzos fueron enfocados en realizar una predicci√≥n m√°s r√°pida. Los tiempos de entrenamiento (te√≥ricos al menos) siguen siendo los mismos o hasta (min√∫sculamente) peores, dado que todas las mejoras siguen llamando al m√©todo `_fit_params` original de `QDA`.\n",
    "\n",
    "La descomposici√≥n/factorizaci√≥n de [Cholesky](https://en.wikipedia.org/wiki/Cholesky_decomposition#Statement) permite factorizar una matriz definida positiva $A = LL^T$ donde $L$ es una matriz triangular inferior. En particular, si bien se asume que $p \\ll n$, invertir la matriz de covarianzas $\\Sigma$ para cada clase impone un cuello de botella que podr√≠a alivianarse. Teniendo en cuenta que las matrices de covarianza son sim√©tricas y salvo degeneraci√≥n, definidas positivas, Cholesky como m√≠nimo deber√≠a permitir invertir la matriz m√°s r√°pido.\n",
    "\n",
    "*Nota: observar que calcular* $A^{-1}b$ *equivale a resolver el sistema* $Ax=b$.\n",
    "\n",
    "### 3) Diferencias entre implementaciones de `QDA_Chol`\n",
    "\n",
    "8. Si una matriz $A$ tiene fact. de Cholesky $A=LL^T$, expresar $A^{-1}$ en t√©rminos de $L$. ¬øC√≥mo podr√≠a esto ser √∫til en la forma cuadr√°tica de QDA?\n",
    "7. Explicar las diferencias entre `QDA_Chol1`y `QDA` y c√≥mo `QDA_Chol1` llega, paso a paso, hasta las predicciones.\n",
    "8. ¬øCu√°les son las diferencias entre `QDA_Chol1`, `QDA_Chol2` y `QDA_Chol3`?\n",
    "9. Comparar la performance de las 7 variantes de QDA implementadas hasta ahora ¬øQu√© se observa?¬øHay alguna de las implementaciones de `QDA_Chol` que sea claramente mejor que las dem√°s?¬øAlguna que sea peor?\n",
    "\n",
    "### 4) Optimizaci√≥n\n",
    "\n",
    "12. Implementar el modelo `TensorizedChol` paralelizando sobre clases/observaciones seg√∫n corresponda. Se recomienda heredarlo de alguna de las implementaciones de `QDA_Chol`, aunque la elecci√≥n de cu√°l de ellas queda a cargo del alumno seg√∫n lo observado en los benchmarks de puntos anteriores.\n",
    "13. Implementar el modelo `EfficientChol` combinando los insights de `EfficientQDA` y `TensorizedChol`. Si se desea, se puede implementar `FasterChol` como ayuda, pero no se contempla para el punto.\n",
    "13. Comparar la performance de las 9 variantes de QDA implementadas ¬øQu√© se observa? A modo de opini√≥n ¬øSe condice con lo esperado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwlW7sqwirdn"
   },
   "source": [
    "# Resolucion del TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) ¬øSobre qu√© paraleliza TensorizedQDA? ¬øSobre las $k$ clases, las $n$ observaciones a predecir, o ambas?\n",
    "\n",
    "  TensorizedQDA paraleliza sobre ambas dimensiones: las $k$ clases y las $n$ observaciones a predecir.\n",
    "  En el modelo QDA original, la predicci√≥n implica un doble bucle: uno sobre las $k$ clases y otro sobre las $n$ observaciones, calculando el score discriminante para cada observaci√≥n y cada clase de forma individual. Esto resulta en una complejidad computacional que escala con $O(n \\cdot k)$.\n",
    "  En cambio, TensorizedQDA utiliza operaciones tensorizadas (con matrices y vectores) para eliminar estos bucles expl√≠citos, aprovechando el paralelismo impl√≠cito de las operaciones matriciales en bibliotecas como NumPy. Esto permite calcular los scores para todas las observaciones y todas las clases simult√°neamente en una sola pasada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agustin:\n",
    "Tensoriza sobre las clases. En la versi√≥n previa el predict_log_conditional actuaba para cada clase individualmente. De esta forma, elimina el for loop de predict_one que operaba sobre las clases (enumerando el vector a_priori)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Analizar los shapes de tensor_inv_covs y tensor_means y explicar paso a paso c√≥mo es que TensorizedQDA llega a predecir lo mismo que QDA.\n",
    "\n",
    "- Shapes esperados:\n",
    "  - tensor_means: Shape $(k, p)$, donde $k$ es el n√∫mero de clases y $p$ es el n√∫mero de features. Representa los vectores de medias para cada clase.\n",
    "  - tensor_inv_covs: Shape $(k, p, p)$, donde cada \"capa\" $(p, p)$ es la matriz inversa de la covarianza para una clase espec√≠fica.\n",
    "\n",
    "- Paso a paso en TensorizedQDA:\n",
    "  1. Entrada: Se recibe un conjunto de observaciones $X$ de shape $(n, p)$, donde $n$ es el n√∫mero de observaciones a predecir.\n",
    "  2. Diferencia con las medias: Se calcula $X - \\mu_k$ para cada clase $k$. Esto se hace restando tensor_means (expandido a $(n, k, p)$ mediante broadcasting) a $X$ (expandido a $(n, k, p)$), resultando en una matriz de diferencias de shape $(n, k, p)$.\n",
    "  3. Forma cuadr√°tica: Para cada clase $k$, se necesita calcular $(x_i - \\mu_k)^T \\Sigma_k^{-1} (x_i - \\mu_k)$ para cada observaci√≥n $x_i$. En TensorizedQDA, esto se logra usando tensor_inv_covs $(k, p, p)$ y las diferencias $(n, k, p)$ mediante una operaci√≥n matricial tensorizada (como einsum), produciendo un tensor de shape $(n, k)$ con los t√©rminos cuadr√°ticos para todas las observaciones y clases.\n",
    "  4. T√©rminos adicionales: Se suman los logaritmos de las probabilidades a priori (log_priors, shape $(k,)$) y los logaritmos de los determinantes de las covarianzas (calculados en el ajuste), ajustados para cada clase.\n",
    "  5. Predicci√≥n: Se toma el argmax a lo largo del eje de las clases (dimensi√≥n $k$) para obtener las predicciones de shape $(n,)$, igual que en QDA.\n",
    "\n",
    "- Equivalencia: La tensorizaci√≥n no cambia la f√≥rmula matem√°tica del discriminante cuadr√°tico, solo reorganiza los c√°lculos para evitar bucles expl√≠citos, logrando el mismo resultado que QDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agustin:\n",
    "\n",
    "  - El shape de tensor_inv_covs es (cantidad de clases, cantidad de features, cantidad de features), siendo en este caso las clases 3 y las features 13, ya que para cada clase genera una matriz cuadrada de las covarianzas entre cada feature (siendo la diagonal la varianza propia de la feature). El shape de tensor_means es (cantidad de clases, cantidad de features, 1), ya que en este caso calcula una media para feature y para cada clase. El cambio con respecto a la versi√≥n previa es que antes cada matriz para cada clase se guardaba en una lista, y eran utilizadas dentro el for loop de predict_one, y ahora est√°n agrupadas en un tensor. Para entender por qu√© llega al mismo resultado, debemos entender c√≥mo funcionan las operaciones @ (np.matmul) y np.linalg.det(), cuando lo aplicamos sobre un tensor que consiste en k matrices apiladas. Lo que hacen ambas operaciones es aplicar la operaci√≥n sobre las k matrices que est√°n apiladas. Operaci√≥n por operaci√≥n ocurre lo siguiente:\n",
    "  - Con unbiased_x.transpose(0,2,1) @ self.tensor_inv_cov @ unbiased_x, con shape de unbiased_x de (3,13,1) y tensor_inv_cov de (3,13,13): -unbiased_x.transpose(0,2,1) convierte el tensor a (3,1,13) -unbiased_x.transpose(0,2,1) @ self.tensor_inv_cov multiplica el tensor de (3,1,13) con el de (3,13,13), donde internamente multiplica los 3 vectores de (1,13) por las 3 matrices de (13,13) y las vuelve a apilar. De esta forma, funciona igual que el for loop que lo hac√≠a en forma separada para las 3, pero numpy lo hace en forma m√°s eficiente al poder paralelizar la operaci√≥n. El resultado es un tensor de (3,1,13) -Finalmente, el tensor de (3,1,13) es multiplicado por el tensor de unbiased_x resultando en un tensor de (3, 1, 1), siendo el segundo t√©rmino de la log verosimilitud para cada una de las clases (al multiplicar por -0.5):\n",
    "\n",
    "$\\log f_j(x) = 12 \\log|\\Sigma_j| - 12(x-\\mu_j)T\\Sigma-1 j(x-\\mu_j) + C$\n",
    "\n",
    " logùëìùëó(ùë•)=‚àí12log|Œ£ùëó|‚àí12(ùë•‚àíùúáùëó)ùëáŒ£‚àí1ùëó(ùë•‚àíùúáùëó)+ùê∂$ \n",
    "  - np.log(LA.det(self.tensor_inv_cov)) la funci√≥n det opera de la misma forma, ya que tensor_inv_cov es de (3,13,13) por lo que para cada una de las 3 clases, genera el determinante de las matrices de (13,13), esto multiplicado por 0.5 nos da el primer t√©rmino de la ecuaci√≥n\n",
    "\n",
    "  - Por √∫ltimo al sumar esto a la log_a_priori, tenemos las posterior, en formato tensor (3,1,1), y para predecir la clase se toma argmax La diferencia es que elimina el loop for de las clases, aplicando las operaciones mediante tensores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementar el modelo FasterQDA (se recomienda heredarlo de TensorizedQDA) de manera de eliminar el ciclo for en el m√©todo predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente c√≥digo elimina el bucle expl√≠cito sobre observaciones al usar einsum para calcular la forma cuadr√°tica en una sola operaci√≥n tensorizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class FasterQDA(TensorizedQDA):\n",
    "    def predict(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        # Aseguro que las dimensiones coincidan\n",
    "        assert n_features == self.tensor_means.shape[1]\n",
    "\n",
    "        # Diferencias: (n, k, p)\n",
    "        diffs = X[:, np.newaxis, :] - self.tensor_means[np.newaxis, :, :]\n",
    "        # Forma cuadr√°tica completa: (n, k) usando einsum\n",
    "        quad_terms = np.einsum('nki,kij,nkj->nk', diffs, self.tensor_inv_covs, diffs)\n",
    "        # Scores: suma de t√©rminos cuadr√°ticos, log priors y log determinantes\n",
    "        scores = -0.5 * quad_terms + self.log_priors[np.newaxis, :] - 0.5 * self.log_dets[np.newaxis, :]\n",
    "        # Predicciones\n",
    "        return np.argmax(scores, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Mostrar d√≥nde aparece la mencionada matriz de $n \\times n$, donde $n$ es la cantidad de observaciones a predecir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  - La matriz de $n \\times n$ aparece en el t√©rmino cuadr√°tico si intentamos calcularlo directamente como $(X - M)^T \\Sigma^{-1} (X - M)$, donde $X$ es $(n, p)$ y $M$ es una matriz de medias repetidas para cada observaci√≥n. En FasterQDA, esto ocurre impl√≠citamente en la operaci√≥n `einsum('nki,kij,nkj->nk', diffs, self.tensor_inv_covs, diffs)`:\n",
    "    - diffs $(n, k, p)$ y tensor_inv_covs $(k, p, p)$ generan un producto intermedio que, si no se reduce inmediatamente, podr√≠a interpretarse como una interacci√≥n entre todas las $n$ observaciones para cada clase, pero einsum colapsa esto a $(n, k)$ directamente, evitando materializar la matriz $n \\times n$ completa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demostrar que $diag(A \\cdot B) = \\sum_{cols} A \\odot B^T = np.sum(A \\odot B^T, axis=1)$\n",
    "\n",
    "Prueba:\n",
    "  Sea $A$ una matriz $(n, p)$ y $B$ una matriz $(n, p)$.\n",
    "  \n",
    "  El producto $A \\cdot B$ resulta en una matriz $(n, n)$, y queremos su diagonal: $diag(A \\cdot B)i = \\sum{j=1}^p A_{ij} B_{ij}$.\n",
    "  \n",
    "  La multiplicaci√≥n elemento a elemento $A \\odot B^T$ da una matriz $(n, p)$, donde $(A \\odot B^T){ij} = A{ij} B_{ji}$.\n",
    "  \n",
    "  Sumando sobre las columnas: $\\sum_{j=1}^p (A \\odot B^T){ij} = \\sum{j=1}^p A_{ij} B_{ji}$, pero necesitamos $B_{ij}$, no $B_{ji}$. Corrigiendo, usamos $A \\odot B$ (no $B^T$):\n",
    "    $(A \\odot B){ij} = A{ij} B_{ij}$, y $\\sum_{j=1}^p (A \\odot B){ij} = \\sum{j=1}^p A_{ij} B_{ij}$, que es exactamente $diag(A \\cdot B)_i$.\n",
    "  \n",
    "  Por lo tanto, $diag(A \\cdot B) = np.sum(A \\odot B, axis=1)$.\n",
    "\n",
    "Correcci√≥n: La consigna menciona $A \\odot B^T$, pero deber√≠a ser $A \\odot B$ para que sea correcto."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
